{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Topics:**\n",
    "\n",
    "- Fisher exact test\n",
    "- Neyman analysis (ATE)\n",
    "- OVB & endogeneity\n",
    "- Difference in differences\n",
    "- Instrumental variables\n",
    "- Probability\n",
    "    - Distributions\n",
    "    - Combinations & permutations\n",
    "- Statistics\n",
    "    - Test statistic\n",
    "    - Type 1 & 2 errors\n",
    "    - Confidence intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "### Test Statistic\n",
    "\n",
    "For a hypothesis test, a researcher collects sample data. From the sample data, the researcher computes a test statistic. If the statistic falls within a specified range of values, the researcher accepts the null hypothesis. The range of values that leads the researcher to accept the null hypothesis is called the region of acceptance.\n",
    "\n",
    "### p-value\n",
    "\n",
    "The p-value is the level of statistical significance in a given statistical test. It is the probability of observing the sample results (or more extreme) given that the null hypothesis is true.\n",
    "\n",
    "Another way to phrase: the p-value is the probability that a difference in a mean score (or other statistic) could have arisen based on the assumption that there is actually no difference.\n",
    "\n",
    "We can reject the null hypothesis at the 95% confidence level when the p-value is less than 0.05.\n",
    "\n",
    "### Hypothesis Tests\n",
    "\n",
    "Key terms:\n",
    "\n",
    "- **Type I error:** false negative (incorrectly rejected null hypothesis / accepted alternative). Probability = $\\alpha$\n",
    "- **Type II error:** false positive (incorrectly accepted null hypothesis / rejected alternative). Probability = $\\beta$\n",
    "\n",
    "\n",
    "- **Significance level:** $\\alpha$ probability of committing Type I error; region of acceptance of a test\n",
    "- **Power:** $1 - \\beta$ probability of $not$ committing a Type II error; likelihood of missing effect being tested for\n",
    "\n",
    "\n",
    "Notes:\n",
    "- Higher beta = lower power, and vice versa\n",
    "- Lower significance level (larger region of acceptance) = lower power (higher chance of not rejecting null hypothesis)\n",
    "- Increase sample size = hypothesis test more sensitive (higher power)\n",
    "- Greater difference between true value and value specified in null hypothesis = greater power of test (effect size)\n",
    "- Increase significance level = larger region of acceptance, higher likelihood of false positive (Type II error), higher power\n",
    "\n",
    "https://stattrek.com/hypothesis-test/power-of-test.aspx\n",
    "\n",
    "### Types of Hypothesis Tests\n",
    "\n",
    "- Fisher exact test: small sample size\n",
    "- T-test: population variance is unknown, small sample size; assumes normal distribution\n",
    "- Z-test: population variance is known; large sample size; assumes normal distribution\n",
    "- Kolmogrov Smirnov test: goodness of fit\n",
    "\n",
    "If no known variance, can use sample variance (average squared distance from the population mean).\n",
    "\n",
    "T-test example in R (single sample): `t.test(sample, mu = 0)`. `p-value = 0.011`, reject null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fisher Exact Test\n",
    "\n",
    "Calculates the p-value empirically (rather than theoretically from a probability distribution).\n",
    "\n",
    "Exact tests calculate the empirical probability of getting an outcome as different or more from the null hypothesis as the outcome you observed in your data. That is the exact p-value.\n",
    "\n",
    "When to use? \n",
    "\n",
    "- Two nominal variables (treatment/control, and measured effect).\n",
    "- Small sample sizes, or \n",
    "\n",
    "Comparison to Chi-Square: exact calculation of significance value, while chi-squared test provides an approximation of significance value based on sampling distribution (= chi-squared distribution). Chi-squared is inadequate when sample sizes are small, or the data are very unequally distributed among cells of the table.\n",
    "\n",
    "#### Compute value of test statistic:\n",
    "\n",
    "$\\bar{\\tau} = |\\bar{Y}_{T}^{obs} - \\bar{Y}_{C}^{obs}|$\n",
    "\n",
    "Example:\n",
    "\n",
    "$|\\tfrac{Y_2^{obs}+Y_6^{obs}+Y_7^{obs}+Y_8^{obs}}{4} - \\tfrac{Y_1^{obs}+Y_3^{obs}+Y_4^{obs}+Y_5^{obs}}{4}| = 0.19425$\n",
    "\n",
    "#### Compute p-value (of test statistic?):\n",
    "\n",
    "$\\dfrac{\\textrm{# test statistics computed for all potential treatment assignments larger than observed test statistic}}{\\textrm{# potential outcomes}}$\n",
    "\n",
    "#### Python & R implementations:\n",
    "Python: `scipy.stats.fisher_exact` for 2x2 contingency table [StackOverflow](https://stackoverflow.com/questions/25368284/fishers-exact-test-for-bigger-than-2-by-2-contingency-table)\n",
    "\n",
    "R: `fisher.test` for nxm table [Docs](https://stat.ethz.ch/R-manual/R-devel/library/stats/html/fisher.test.html)\n",
    "\n",
    "#### Notes\n",
    "\n",
    "http://www.biostathandbook.com/fishers.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-value: 0.6643639131198411\n",
      "p-value: 0.5490706532964028\n",
      "p-value: 0.000999000999000999\n"
     ]
    }
   ],
   "source": [
    "import rpy2.robjects.numpy2ri\n",
    "from rpy2.robjects.packages import importr\n",
    "rpy2.robjects.numpy2ri.activate()\n",
    "\n",
    "stats = importr('stats')\n",
    "\n",
    "m = np.array([[4,4],[4,5],[10,6]])\n",
    "res = stats.fisher_test(m)\n",
    "print('p-value: {}'.format(res[0][0]))\n",
    "\n",
    "m = np.array([[15, 8],[20, 5],[14, 7], [6, 1]])\n",
    "res = stats.fisher_test(m)\n",
    "print('p-value: {}'.format(res[0][0]))\n",
    "\n",
    "# Couldn't get this to work\n",
    "m = np.array([\n",
    "    [1, 850, 150],\n",
    "    [1, 990, 10],\n",
    "    [1, 1000, 0],\n",
    "    [1, 760, 240],\n",
    "    [0, 260, 740],\n",
    "    [0, 450, 550],\n",
    "    [0, 970, 30],\n",
    "    [0, 720, 280]\n",
    "])\n",
    "res = stats.fisher_test(m)\n",
    "#res = stats.fisher_test(m, simulate_p_value = True, B = 1000)\n",
    "print('p-value: {}'.format(res[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neyman Analysis\n",
    "\n",
    "When to use Neyman analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Difference in Differences (DiD)\n",
    "\n",
    "Calculate by hand by taking mean outcome of group A in both periods and take their difference. Then subtract the same for group B, and get the treatment effect on group A.\n",
    "\n",
    "Calculate via linear regression by taking the coefficient on the interaction between a treatment dummy variable and time dummy variable.\n",
    "\n",
    "\n",
    "### Endogeneity\n",
    "\n",
    "Correlation between X variable and the error term in the model.\n",
    "\n",
    "### Instrumental variables\n",
    "\n",
    "Correct for endogeneity by making another, different, causal assumption.\n",
    "\n",
    "### Omitted variable bias (OVB)\n",
    "\n",
    "Include potentially correlated variables in regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability\n",
    "\n",
    "In Python: https://web.stanford.edu/class/cs109/handouts/pythonForProbability.html\n",
    "\n",
    "### Distributions\n",
    "\n",
    "**Bernoulli:** discrete probability distribution of r.v. which takes value 1 with probability *p</t>* and value 0 with probability *q = 1 - p*. Special case of binomial distribution where a single trial is conducted.\n",
    "\n",
    "**Binomial:** number successes *k</t>* in number of trials/draws *n</t>* drawn with replacement from population of size *N</t>* with probability of success *p</t>*.\n",
    "\n",
    "**Geometric:** number *X</t>* of Bernoulli trials needed to get one success (*shifted geometric*), or the number *Y = X - 1* failures before the first success.\n",
    "\n",
    "**Hypergeometric:** discrete distribution of probability of *k</t>* successes in *n</t>* trials/draws from a population of size *N</t>* that contains exactly *K</t>* objects, without replacement. Contrast to binomial which is with replacement.\n",
    "\n",
    "- Exponential\n",
    "- Poisson\n",
    "- Uniform\n",
    "- Gaussian\n",
    "\n",
    "Relationships:\n",
    "\n",
    "- Binomial v.s. Hypergeometric = successes with replacement v.s. without replacement\n",
    "- Bernoulli v.s. Binomial = one trial v.s. \n",
    "\n",
    "### Combinations & Permutations\n",
    "\n",
    "**Combination:** nCk (n-choose-k) unordered pairs\n",
    "\n",
    "**Permutation:** ordered pairs\n",
    "\n",
    "n^k?\n",
    "\n",
    "### Maximum Likelihood Estimator (MLE)\n",
    "\n",
    "https://www.projectrhea.org/rhea/index.php/Maximum_Likelihood_Estimation_Analysis_for_various_Probability_Distributions\n",
    "https://math.stackexchange.com/questions/411145/maximum-likelihood-estimation-of-a-b-for-a-uniform-distribution-on-a-b?noredirect=1&lq=1\n",
    "\n",
    "For uniform: \n",
    "\n",
    "- $[0, \\theta]$: $f(xi) = \\dfrac{1}{\\theta}$\n",
    "- $[a, b]$: $\\hat{a}_{MLE} = min(X_1,...,X_n)$, $\\hat{b}_{MLE} = max(X_1,...,X_n)$\n",
    "\n",
    "### Central Limit Theorem\n",
    "\n",
    "Setup: each $X_i$ is a Bernoulli trial with probability $p$ of success. Therefore the sum is a binomial distribution $\\sum{X_i} = X ~ Bin(n, p)$ where the population has a mean $\\mu = n*p$ and standard deviation $\\sigma = \\sqrt{n*p*(1-p)}$. \n",
    "\n",
    "For a sufficiently large number of trials with replacement/sample size (n >= 30), or when the population is normally distributed, then the distribution of sample mean will be approximately normally distributed.\n",
    "\n",
    "- Probability that X is <= x $\\Phi(\\frac{x - \\mu}{\\sigma})$\n",
    "- Probability that X is > x is $1 - \\Phi(\\frac{x - \\mu}{\\sigma})$\n",
    "- Probability that X is >= x is $1 - \\Phi(\\frac{x - 0.5 - \\mu}{\\sigma})$\n",
    "- Probability that X is >= x and <= y is $\\Phi(\\frac{y + 0.5 - \\mu}{\\sigma}) - \\Phi(\\frac{x - 0.5 - \\mu}{\\sigma})$\n",
    "\n",
    "Probability , and the probability that X is <= \n",
    "\n",
    "https://docs.scipy.org/doc/scipy/reference/tutorial/stats.html\n",
    "https://math.stackexchange.com/questions/1784469/using-central-limit-theorem-to-estimate-probability/1784499\n",
    "\n",
    "### Calculating probabilities in Python/R\n",
    "\n",
    "- Probability that a variable has a value LESS than or equal, take cumulative density function (CDF). GREATER than = 1-CDF or survival function.\n",
    "- Value needed to provide an X% probability, use percent point function (PPF).\n",
    "- Probability of taking on a exactly specific value, use the probability density function (PDF).\n",
    "\n",
    "Normal distribution operations using `scipy.stats.norm` which assumes mean = 0, SD = 1\n",
    "- Value of X where 95% of value is included (left/lower-tail probability): `norm.ppf(0.95)`\n",
    "- Probability of X being less than or equal to 1.64: `norm.cdf(1.64)`\n",
    "- Density points (values of X) where 95% of the distribution is included: X >= `norm.ppf(.025)` and X <= `norm.ppf(.975)` (+/- 1.96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assumptions: {'mean': 200.0, 'variance': 100.0, 'sd': 10.0, 'x': 209.0}\n",
      "Z-score: 0.9\n",
      "Probability X <= 209.0: 0.82\n",
      "Probability X > 209.0: 0.18\n"
     ]
    }
   ],
   "source": [
    "# Calculating probability using CLT\n",
    "# Question 3.2\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html\n",
    "from scipy.stats import norm\n",
    "from math import sqrt\n",
    "\n",
    "p = 0.5\n",
    "q = 1 - p\n",
    "n = 400\n",
    "mean = p * n\n",
    "variance = p * q * n\n",
    "sd = sqrt(variance)\n",
    "x = (0.525 * n) - 1 # 52.5% * 400 people polled = 210\n",
    "\n",
    "print('Assumptions:', { 'mean': mean, 'variance': variance, 'sd': sd, 'x': x })\n",
    "\n",
    "z_score = (x - mean) / sd\n",
    "print('Z-score:', z_score)\n",
    "\n",
    "prb = norm.cdf(z_score)\n",
    "print(f'Probability X <= {x}:', round(prb, 2))\n",
    "\n",
    "prb = 1 - prb\n",
    "print(f'Probability X > {x}:', round(prb, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "LaTeX reference: https://kapeli.com/cheat_sheets/LaTeX_Math_Symbols.docset/Contents/Resources/Documents/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1 150 0.533812\n",
      "Option 1 155 0.651387\n",
      "Option 1 157 0.694566\n",
      "Option 1 158 0.715093\n",
      "Option 2 158 0.7150928933565812\n",
      "Option 3 158\n"
     ]
    }
   ],
   "source": [
    "# Exam Questions\n",
    "\n",
    "# Q2\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "# https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.hypergeom.html\n",
    "# https://math.stackexchange.com/questions/2595744/hypergeometric-distribution\n",
    "\n",
    "# Using 1-CDF/SF and draw size options\n",
    "M = 1200 # population size\n",
    "n = 400 # number of matching objects\n",
    "k = 50 # number of successes\n",
    "samples = [150, 155, 157, 158]\n",
    "for N in samples:\n",
    "    prb = hypergeom.sf(k-1, M, n, N)\n",
    "    print('Option 1', N, f'{prb:f}')\n",
    "    \n",
    "# Alternative without draw size options to select from\n",
    "target_prb = 0.7\n",
    "draw_size = 0\n",
    "required_num_successes = 50\n",
    "prb = 0\n",
    "while prb < target_prb:\n",
    "    draw_size += 1\n",
    "    prb = hypergeom.sf(required_num_successes-1, M, n, draw_size)\n",
    "    \n",
    "print('Option 2', draw_size, prb)\n",
    "    \n",
    "# Alternative using PPF\n",
    "target_prb = 0.7\n",
    "draw_size = 0 # N\n",
    "required_num_successes = 50\n",
    "k = 0\n",
    "while k != required_num_successes:\n",
    "    draw_size += 1\n",
    "    k = hypergeom.ppf(1-target_prb, M, n, draw_size)\n",
    "    \n",
    "print('Option 3', draw_size) # we're aiming for 50 in problem setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.0\n"
     ]
    }
   ],
   "source": [
    "# n-choose-k\n",
    "from scipy.special import comb\n",
    "print(comb(6, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
